# notebook cell: train_and_save.ipynb
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
import joblib, json

calories = pd.read_csv("calories.csv")
exercise = pd.read_csv("exercise.csv")

# Standardize column names
calories.columns = calories.columns.str.strip().str.lower()
exercise.columns = exercise.columns.str.strip().str.lower()

# Merge on user_id
df = pd.merge(exercise, calories, on="user_id")

print(df.head())
print(df.columns.tolist())




FEATURES = ["age", "height", "weight", "duration", "heart_rate", "body_temp"]
TARGET = "calories"

X = df[FEATURES]
y = df[TARGET]






# 2) Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 3) Build pipeline with preprocessing + model
pipeline = Pipeline([
    ("scaler", StandardScaler()),
    ("model", RandomForestRegressor(n_estimators=100, random_state=42))
])

pipeline.fit(X_train, y_train)

# 4) Evaluate (optional)
from sklearn.metrics import mean_absolute_error, r2_score
y_pred = pipeline.predict(X_test)
print("MAE:", mean_absolute_error(y_test, y_pred))
print("R2:", r2_score(y_test, y_pred))

# 5) Save pipeline and feature order
joblib.dump(pipeline, "models/calorie_pipeline.pkl")
with open("models/feature_names.json", "w") as f:
    json.dump(FEATURES, f)



